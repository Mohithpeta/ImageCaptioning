Image Captioning with BLIP ðŸš€
This project implements an Automated Image Captioning System using BLIP (Bootstrapped Language-Image Pretraining). It processes uploaded images and generates descriptive captions using a FastAPI backend and a React + TypeScript frontend. The BLIP model runs on PyTorch, leveraging GPU acceleration for fast and accurate predictions. The backend handles image uploads, processes them, and returns captions via an API, while the frontend provides an intuitive interface for users to upload images and receive descriptions. Tech stack: FastAPI, React, TypeScript, PyTorch, and Transformers. Deployed locally with future plans for cloud hosting. ðŸš€
